{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Class Definitions\n",
    "\n",
    "class Quote:\n",
    "    def __init__(self, quote, category):\n",
    "        self.quote = quote\n",
    "        self.category = category\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/reduced_quotes.csv')\n",
    "\n",
    "df.dropna()\n",
    "\n",
    "quotes = []\n",
    "\n",
    "df['processed_category'] = df['category'].apply(lambda x: ' '.join(str(x).split(', ')))\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    quotes.append(Quote(row['quote'], row['processed_category']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499709\n",
      "334805\n",
      "The sting of her abandonment had not lessened through the years, and I suspected it would never go away. Occasionally, I could see agony in her eyes, the shadows that flickered in the background. If I could, I'd take her pain and make it my own. I'd swallow it like a bitter pill and live with the consequences.\n",
      "love relationship suffering\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(len(quotes))\n",
    "\n",
    "training, test = train_test_split(quotes, test_size=0.33, random_state=42, shuffle=True)\n",
    "\n",
    "print(len(training))\n",
    "\n",
    "x_train = [q.quote for q in training]\n",
    "y_train = [q.category for q in training]\n",
    "\n",
    "x_train = [\"\" if pd.isna(text) else str(text) for text in x_train]\n",
    "\n",
    "\n",
    "x_test = [q.quote for q in test]\n",
    "y_test = [q.category for q in test]\n",
    "\n",
    "print(x_test[0])\n",
    "print(y_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "train_x_vectors = tfidf_vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334805, 127983)\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "['00' '000' '0000' ... 'ﬂowersraised' 'ﬂows' 'ﬂush']\n"
     ]
    }
   ],
   "source": [
    "print(train_x_vectors.shape)\n",
    "print(train_x_vectors[0].toarray())\n",
    "print(tfidf_vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
